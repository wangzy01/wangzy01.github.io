<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ziyi Wang (王梓懿) Peking University</title>

    <meta name="author" content="Ziyi Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/ys.jpg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-XTNP10E5TM"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-XTNP10E5TM');
    </script> -->

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                
                <p class="name" style="text-align: center;">
                  Ziyi Wang (王梓懿)
                </p>
                
                <p>I'm currently a first-year M.S. student at <a href="https://www.pku.edu.cn/">Peking University</a>, Shenzhen Graduate School, majoring in Computer Science and Technology, advised by Prof. <a href="https://scholar.google.com/citations?user=woX_4AcAAAAJ">Mengyuan Liu</a> and Prof. <a href="https://scholar.google.com/citations?user=WLMUAjsAAAAJ">Hong Liu</a>. I am broadly interested in computer vision and deep learning.
                </p>
                
                <p>Before that, I received my B.S. degree in Computer Science and Technology (ranked top 1 out of 289 students) from Ocean University of China in 2024.</p>
                </p>


                <p style="text-align:center">
                  <a href="mailto:ziyiwang@stu.pku.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=PtLVjbMAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/wangzy01">GitHub</a>
                </p>

              </td>
              <td style="padding:2.5%;width:45%;max-width:45%">
                <img style="width:60%;max-width:60%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/wangziyi.jpg" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>
                    
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding: 20px 20px 0;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  <strong> * indicates equal contribution, # indicates corresponding author</strong>
                </p>
              </td>
            </tr>
          </tbody></table>

              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                
                <tr>
                  <td style="padding:10px;width:25%;vertical-align:middle"> 
                    <img src="images/mp1.png" alt="sparseflex" width="210" height="140" style="border-style: none; object-fit: contain;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">MP1: MeanFlow Tames Policy Learning in 1-step for Robotic Manipulation</span>
                    <br>
                        Juyi Sheng*,
                        <strong>Ziyi Wang*</strong>,
                        <a href="https://scholar.google.com/citations?user=TFBbgIQAAAAJ">Peiming Li</a>,
                        <a href="https://scholar.google.com/citations?user=woX_4AcAAAAJ">Mengyuan Liu#</a>
                    <br>
                    <em>Preprint</em>
                    <br>
                    <a href="https://arxiv.org/abs/2507.10543">arXiv</a>
                    /
                    <a href="https://github.com/LogSSim/MP1">Code</a>
                  </td>
                </tr>


                <tr>
                  <td style="padding:10px;width:25%;vertical-align:middle"> 
                    <img src="images/active.png" alt="sparseflex" width="210" height="140" style="border-style: none; object-fit: contain;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">(ACTIVE) Recognizing Actions from Robotic View for Natural Human-Robot Interaction</span>
                    <br>
                        <strong>Ziyi Wang</strong>,
                        <a href="https://scholar.google.com/citations?user=TFBbgIQAAAAJ">Peiming Li</a>,
                        <a href="https://scholar.google.com/citations?user=WLMUAjsAAAAJ">Hong Liu</a>,
                        Zhichao Deng,
                        <a href="https://scholar.google.com/citations?user=sEeImYgAAAAJ">Can Wang</a>,
                        <a href="https://scholar.google.com/citations?user=Q5Ild8UAAAAJ">Jun Liu</a>,
                        <a href="https://scholar.google.com/citations?user=fJ7seq0AAAAJ">Junsong Yuan</a>,
                        <a href="https://scholar.google.com/citations?user=woX_4AcAAAAJ">Mengyuan Liu#</a>
                    <br>
                    <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
                    <br>
                    <a href="https://arxiv.org/abs/2507.22522">arXiv</a>
                    /
                    <a href="https://wangzy01.github.io/ACTIVE/index.html">Project Page</a>
                    /
                    <a href="https://github.com/wangzy01/ACTIVE-Action-from-Robotic-View">Code</a>
                  </td>
                </tr>
 

                <tr>
                  <td style="padding:10px;width:25%;vertical-align:middle"> 
                    <img src="images/ustssm.png" alt="sparseflex" width="210" height="140" style="border-style: none; object-fit: contain;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">UST-SSM: Unified Spatio-Temporal State Space Models for Point Cloud Video Modeling</span>
                    <br>
                        <a href="https://scholar.google.com/citations?user=TFBbgIQAAAAJ">Peiming Li</a>,
                        <strong>Ziyi Wang</strong>,
                        Yulin Yuan,
                        <a href="https://scholar.google.com/citations?user=WLMUAjsAAAAJ">Hong Liu</a>,
                        <a href="https://scholar.google.com/citations?user=oV70ZoQAAAAJ">Xiangming Meng</a>,
                        <a href="https://scholar.google.com/citations?user=fJ7seq0AAAAJ">Junsong Yuan</a>,
                        <a href="https://scholar.google.com/citations?user=woX_4AcAAAAJ">Mengyuan Liu#</a>
                    <br>
                    <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
                    <br>
                    <a href="https://github.com/wangzy01/UST-SSM">Code</a>
                  </td>
                </tr>

                <tr>
                  <td style="padding:10px;width:25%;vertical-align:middle"> 
                    <img src="images/clickdiff.png" alt="sparseflex" width="210" height="140" style="border-style: none; object-fit: contain;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">ClickDiff: Click to Induce Semantic Contact Map for Controllable Grasp Generation with Diffusion Models</span>
                    <br>
                        <a href="https://scholar.google.com/citations?user=TFBbgIQAAAAJ"></a>Peiming Li*</a>,
                        <strong>Ziyi Wang*</strong>,
                        <a href="https://scholar.google.com/citations?user=woX_4AcAAAAJ">Mengyuan Liu#</a>,
                        <a href="https://scholar.google.com/citations?user=WLMUAjsAAAAJ">Hong Liu</a>,
                        <a href="https://scholar.google.com/citations?user=TuEwcZ0AAAAJ">Chen Chen</a>
                    <br>
                    <em>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2024 (<font color="#dd0000">Oral Presentation</font>)
                    <br>
                    <a href="https://arxiv.org/abs/2407.19370">arXiv</a>
                    /
                    <a href="https://github.com/wangzy01/ClickDiff">Code</a>
                  </td>
                </tr>
                
                

                <tr>
                  <td style="padding10px;width:25%;vertical-align:middle"> 
                    <img src="images/glaformer.png" alt="sparseflex" width="210" height="140" style="border-style: none; object-fit: contain;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">Global and Local Attention-Based Transformer for Hyperspectral Image Change Detection</span>
                    <br>
                        <strong>Ziyi Wang</strong>,
                        <a href="https://scholar.google.com/citations?user=k91CLXQAAAAJ">Feng Gao#</a>
                        <a href="https://scholar.google.com/citations?user=iPYdUpAAAAAJ">Junyu Dong</a>,
                        <a href="https://scholar.google.com/citations?user=0OdKQoQAAAAJ">Qiang Du</a>
                    <br>
                    <em>IEEE Geoscience and Remote Sensing Letters (<strong>GRSL</strong>)</em>, 2024
                    <br>
                    <a href="https://arxiv.org/abs/2411.14109">arXiv</a>
                    /
                    <a href="https://github.com/summitgao/GLAFormer">Code</a>
                  </td>
                </tr>


          
    
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Selected Honors & Awards</h2>
                <br>
                <li> National Scholarship
                  <div style="float:right; text-align:right"><em>2023</em></div>
              </li>
                <li> Presidential Schorlarship (特等奖学金) , 10/4,000+
                  <div style="float:right; text-align:right"><em>2023</em></div>
              </li>
              <li> The CCF Elite Collegiate Award
                  <div style="float:right; text-align:right"><em>2023</em></div>
              </li>
              <li> Outstanding Graduate of Shandong Province
                  <div style="float:right; text-align:right"><em>2024</em></div>
              </li>
              <li> ICPC Asia Xi'an Regional Contest, Bronze Medal
                  <div style="float:right; text-align:right"><em>2023</em></div>
              </li>
              <li> ICPC China Shandong Provincial Programming Contest, Silver Medal
                  <div style="float:right; text-align:right"><em>2023</em></div>
              </li>
              <li> Lanqiao Cup National Contest (C++ A Group), Third Prize
                <div style="float:right; text-align:right"><em>2022</em></div>
              </li>
              </td>
            </tr>
          </tbody></table>
      
  </body>
</html>
